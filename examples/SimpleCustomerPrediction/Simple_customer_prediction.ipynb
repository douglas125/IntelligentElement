{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V4ENkHk5JBrJ"
   },
   "source": [
    "# Simple Customer Prediction\n",
    "\n",
    "This notebook shows a simple example of how to use Intelligent Element to train a model that handles data with nested structures.\n",
    "\n",
    "In this simulated example, we will predict whether a customer of a restaurant will come back next week.\n",
    "\n",
    "## Features\n",
    "\n",
    "Features are:\n",
    "\n",
    "- client age (12-70)\n",
    "- client gender (0-male, 1-female)\n",
    "- number of children (0-5)\n",
    "- client relative income (continous from 0 - low income to 1 - high income)\n",
    "- List of whether the customer was present in the last 30 days containing:\n",
    "    - customer present? (1-yes, 0-no)\n",
    "    - customer rating (from  0-bad to 1-excellent)\n",
    "    - time spent in restaurant (0-as little as possible, 1-much longer than necessary)\n",
    "    - List of items ordered \n",
    "        - Price (0-cheap for item to 1-expensive for item);\n",
    "        - Average quality rating (0-bad to 1-excellent);\n",
    "    \n",
    "The last element of the list is yesterday, the second to last is the day before and so on.\n",
    "\n",
    "## Rule Set\n",
    "\n",
    "To generate the simulated data, a set of rules will be created. Let's start with some assumptions:\n",
    "\n",
    "- Young people (<25) prefer to spend small amounts of time in the restaurant;\n",
    "- Older people (>45) prefer to spend longer in the restaurant;\n",
    "- No one likes to spend too much time in the restaurant;\n",
    "- Everyone likes lower prices and better quality products;\n",
    "- Men value price more;\n",
    "- Women value quality more;\n",
    "- If the quality of one or more products is too low (<0.1) it has a very significant negative impact;\n",
    "- Customers are more likely to come back if they come often and give a high rating often;\n",
    "- When clients give a good rating at a given day, it means that they liked that particular combination and are more likely to come back;\n",
    "- The more children, the less likely a customer to come next week.\n",
    "\n",
    "Note that a deep learning model will need to learn how to relate data from the internal list with, for example, gender. It will also need to \"remember\" if the score of a given product was too low.\n",
    "\n",
    "Based on these assumptions, we create the following \"comeback\" score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_wtC4uCfJBrN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CyzViJ7NJBrU"
   },
   "outputs": [],
   "source": [
    "def order_score(order_avg, order_toobad, gender, score, timespent, age):\n",
    "    if gender == 0:\n",
    "        #men value price\n",
    "        s = (1-order_avg[0])*1.4+order_avg[1]\n",
    "    else:\n",
    "        #women value quality\n",
    "        s = order_avg[0]+1.5*order_avg[1]\n",
    "        \n",
    "    s *= np.exp(-order_toobad)\n",
    "    s *= (1+score)\n",
    "    \n",
    "    if timespent >= 0.9:\n",
    "        s *= 0.4\n",
    "    else:\n",
    "        if timespent >= 0.6 and age >= 45:\n",
    "            s *= 1.1\n",
    "        elif timespent <= 0.3 and age <= 25:\n",
    "            s *= 1.3\n",
    "    return s\n",
    "\n",
    "def customer_score(c):\n",
    "    #pick features from last visits\n",
    "    last30 = [ [x['present'], x['rating'], x['time_spent']] for x in c['last_30'] if x['present']==1]\n",
    "    \n",
    "    order_data = [x['order'] for x in c['last_30'] if x['present']==1]\n",
    "    order_avgs = [np.mean(x, axis=0) for x in order_data]\n",
    "    \n",
    "    #how many orders were too bad?\n",
    "    order_toobad = np.array([(np.sum(np.array(x)<=0.1,axis=0)>=1).astype(int) for x in order_data])[:,1]\n",
    "    order_scores = [order_score(order_avgs[k], order_toobad[k], c['gender'], last30[k][1], last30[k][2], c['age'])  for k in range(len(last30))]\n",
    "    \n",
    "    s = np.mean(order_scores)\n",
    "\n",
    "    s -= c['n_children']*0.1\n",
    "    s *= (1+c['income'])\n",
    "    \n",
    "    if s<0:\n",
    "        s=0\n",
    "    #print(order_scores)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8EhsbgVNJBrZ"
   },
   "source": [
    "Let's simulate some clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dZLJRe7jJBrb",
    "outputId": "ccb5dc9c-a937-4930-fc82-5f51f60b2ca0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32061677928864923"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a client that is not likely to return\n",
    "customer_data={'age': 55, 'gender' : 0, 'n_children' : 4, 'income' : 0.3,\n",
    "               'last_30' : [\n",
    "                   {'present' : 1, 'rating':0.3,'time_spent':0.3, 'order': [ [0.8,0.3], [0.6,0.2] ] },\n",
    "                   {'present' : 0, 'rating':0,  'time_spent':0,   'order': [ [0,0] ] },\n",
    "                   {'present' : 0, 'rating':0,  'time_spent':0,   'order': [ [0,0] ] },\n",
    "                   {'present' : 1, 'rating':0.4,'time_spent':0.7, 'order': [ [0.8,0.8], [0.6,0.1] ] },\n",
    "                   {'present' : 0, 'rating':0,  'time_spent':0,   'order': [ [0,0] ] },\n",
    "                   {'present' : 1, 'rating':0.2,'time_spent':0.3, 'order': [ [0.9,0.2], [0.8,0.2], [0.7,0.2] ] }\n",
    "               ]\n",
    "              }\n",
    "customer_score(customer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JMKytjEKJBrk",
    "outputId": "fb33fab7-5fed-4a85-9c5e-70754f4d9d66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.982755555555555"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a client that is likely to return\n",
    "customer_data={'age': 22, 'gender' : 0, 'n_children' : 2, 'income' : 0.6,\n",
    "               'last_30' : [\n",
    "                   {'present' : 1, 'rating':0.7,'time_spent':0.4, 'order': [ [0.8,0.8], [0.6,0.9] ] },\n",
    "                   {'present' : 1, 'rating':0.8,'time_spent':0.4, 'order': [ [0.8,0.8], [0.6,0.9] ] },\n",
    "                   {'present' : 0, 'rating':0,  'time_spent':0,   'order': [ [0,0] ] },\n",
    "                   {'present' : 1, 'rating':0.9,'time_spent':0.3, 'order': [ [0.3,0.8], [0.6,0.8], [0.6,0.7] ] }\n",
    "               ]\n",
    "              }\n",
    "customer_score(customer_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U5-HjNlQJBrr"
   },
   "source": [
    "# Data Generation\n",
    "\n",
    "Let us generate a simple synthetic dataset and check the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S5KIawt3JBrs"
   },
   "outputs": [],
   "source": [
    "def gen_client_data():\n",
    "    ans = {'age' :        np.random.randint(12,70),\n",
    "           'gender' :     np.random.randint(2),\n",
    "           'n_children' : np.random.randint(6),\n",
    "           'income' :     np.random.uniform(0,1),\n",
    "           'last_30' :     []\n",
    "          }\n",
    "    \n",
    "    n_lastvisits = np.random.randint(2,31)\n",
    "    for k in range(n_lastvisits):\n",
    "        if np.random.uniform(0,1) < 0.6 and len(ans['last_30']) > 0:\n",
    "            ans['last_30'].append( {'present' : 0, 'rating':0,  'time_spent':0,   'order': [[0,0]] } )\n",
    "        else:\n",
    "            day_data = { \n",
    "                         'present' :    1,\n",
    "                         'rating' :     np.random.uniform(0,1),\n",
    "                         'time_spent' : np.random.uniform(0,1),\n",
    "                       }\n",
    "            \n",
    "            n_order = np.random.randint(5,16)\n",
    "            day_data['order'] = [ [np.random.uniform(0,1),np.random.uniform(0,1)] for k in range(n_order) ]\n",
    "\n",
    "            ans['last_30'].append(day_data)\n",
    "    \n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "colab_type": "code",
    "id": "ouGOUCo2JBrx",
    "outputId": "143ff956-a49c-48ca-a9e2-9db340b8f213",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([12., 13., 19., 32., 40., 45., 64., 82., 84., 76., 71., 72., 73.,\n",
       "        61., 43., 43., 27., 33., 30., 21., 11., 13.,  5.,  6.,  5.,  5.,\n",
       "         4.,  1.,  2.,  2.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         2.]),\n",
       " array([0.        , 0.11391494, 0.22782988, 0.34174482, 0.45565976,\n",
       "        0.5695747 , 0.68348964, 0.79740458, 0.91131952, 1.02523446,\n",
       "        1.13914939, 1.25306433, 1.36697927, 1.48089421, 1.59480915,\n",
       "        1.70872409, 1.82263903, 1.93655397, 2.05046891, 2.16438385,\n",
       "        2.27829879, 2.39221373, 2.50612867, 2.62004361, 2.73395855,\n",
       "        2.84787349, 2.96178843, 3.07570337, 3.18961831, 3.30353324,\n",
       "        3.41744818, 3.53136312, 3.64527806, 3.759193  , 3.87310794,\n",
       "        3.98702288, 4.10093782, 4.21485276, 4.3287677 , 4.44268264,\n",
       "        4.55659758]),\n",
       " <a list of 40 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD4CAYAAAAjKGdbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9P8Ww40rNhtlTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1473752f98>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "client_data=[gen_client_data() for k in range(1000)]\n",
    "client_scores=[customer_score(c) for c in client_data]\n",
    "plt.hist(client_scores, bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aqLNUJAHJBr4"
   },
   "outputs": [],
   "source": [
    "def gen_client_dataset(n=1000, threshold = 1.5):\n",
    "    client_data   =[gen_client_data() for k in range(n)]\n",
    "    client_returns=[int(customer_score(c)>=threshold) for c in client_data]\n",
    "    \n",
    "    return client_data, client_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CToxXjwMJBr-"
   },
   "outputs": [],
   "source": [
    "x_train, y_train = gen_client_dataset(n=150000)\n",
    "x_val, y_val     = gen_client_dataset(n=1200)\n",
    "x_test, y_test   = gen_client_dataset(n=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "afY9PXg2JBsF"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OxS0AVRcJBsG",
    "outputId": "91179a3b-edac-4842-a5a3-1c06a76dc291"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#learning\n",
    "from keras import Model\n",
    "from keras import layers as L\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "#add two parent levels to path\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(os.path.dirname(currentdir))\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import IntelligentElement as IE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSFCucbkJBsQ"
   },
   "outputs": [],
   "source": [
    "nn_hidden_sizes=48\n",
    "nn_depth=12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SLcpJFe1JBsY"
   },
   "source": [
    "# order data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "p5nZdLHGJBsc",
    "outputId": "ed7e508e-7c81-4061-d6c3-320278943fb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, None, None, 2)     0         \n",
      "_________________________________________________________________\n",
      "lstm_order (TimeDistributed) (None, None, 48)          9984      \n",
      "=================================================================\n",
      "Total params: 9,984\n",
      "Trainable params: 9,984\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "Retrieved model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inp_order_ie (InputLayer)    (None, None, None, 2)     0         \n",
      "_________________________________________________________________\n",
      "m_order_ie (Model)           (None, None, 48)          9984      \n",
      "=================================================================\n",
      "Total params: 9,984\n",
      "Trainable params: 9,984\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def preproc_order(rec):\n",
    "    orders = [np.array(v['order']) for v in rec['last_30']]    \n",
    "    return orders\n",
    "\n",
    "#model\n",
    "order_shape = (None, None, 2)\n",
    "inp = L.Input( order_shape )\n",
    "x = inp\n",
    "\n",
    "#for k in range(nn_depth):\n",
    "#    x = L.Dense(nn_hidden_sizes,activation='relu')(x)\n",
    "    \n",
    "#x1 = L.TimeDistributed(L.GlobalAveragePooling1D(), name='td_avgpooling')(x)\n",
    "#x2 = L.TimeDistributed(L.GlobalMaxPooling1D(), name='td_maxpooling')(x)\n",
    "#x  = L.Concatenate()([x1,x2])\n",
    "x = L.TimeDistributed(L.CuDNNLSTM(nn_hidden_sizes),name='lstm_order')(x)\n",
    "\n",
    "order_model = Model(inputs=inp, outputs=x)\n",
    "order_model.summary()\n",
    "\n",
    "order_ie = IE.IntelligentElement(x_train, order_model, order_shape, preprocess_function=preproc_order, \n",
    "                                val_data=x_val, test_data=x_test, name='order_ie')\n",
    "\n",
    "m, ii, oo = order_ie.retrieve_model_inputs_outputs()\n",
    "print('\\n\\nRetrieved model')\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sjgk36SOJBsi"
   },
   "source": [
    "# days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "id": "Ez7jOpB_JBsj",
    "outputId": "2c439046-f2ca-44db-fbbc-71128e6d476a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, None, 51)          0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 48)                19392     \n",
      "=================================================================\n",
      "Total params: 19,392\n",
      "Trainable params: 19,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "Retrieved model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inp_order_ie (InputLayer)       (None, None, None, 2 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "m_order_ie (Model)              (None, None, 48)     9984        inp_order_ie[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inp_day_ie (InputLayer)         (None, None, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, 51)     0           m_order_ie[2][0]                 \n",
      "                                                                 inp_day_ie[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "m_day_ie (Model)                (None, 48)           19392       concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 29,376\n",
      "Trainable params: 29,376\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def preproc_day(rec):\n",
    "    day_data = [np.array([x['present'], x['rating'], x['time_spent']]) for x in rec['last_30']]\n",
    "    return day_data\n",
    "\n",
    "#model\n",
    "day_shape = (None, 3)\n",
    "inp = L.Input( (None, order_ie.model.output_shape[-1] + day_shape[-1]) )\n",
    "x = inp\n",
    "\n",
    "#for k in range(nn_depth):\n",
    "#    x = L.Dense(nn_hidden_sizes,activation='relu')(x)\n",
    "#x = L.GlobalAveragePooling1D(name='day_pool')(x)\n",
    "x = L.CuDNNLSTM(nn_hidden_sizes)(x)\n",
    "\n",
    "day_model = Model(inputs=inp, outputs=x)\n",
    "day_model.summary()\n",
    "\n",
    "day_ie = IE.IntelligentElement(x_train, day_model, day_shape, preprocess_function=preproc_day, children_ie=order_ie,\n",
    "                                val_data=x_val, test_data=x_test, name='day_ie')\n",
    "\n",
    "m, ii, oo = day_ie.retrieve_model_inputs_outputs()\n",
    "print('\\n\\nRetrieved model')\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7TSzVwwJBsq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Cm9uGj8JBsw"
   },
   "source": [
    "## root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "colab_type": "code",
    "id": "KfuYo9zwJBsz",
    "outputId": "e043c026-d19b-4caf-b074-db2d1ef88e27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Retrieved model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inp_order_ie (InputLayer)       (None, None, None, 2 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "m_order_ie (Model)              (None, None, 48)     9984        inp_order_ie[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inp_day_ie (InputLayer)         (None, None, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, 51)     0           m_order_ie[3][0]                 \n",
      "                                                                 inp_day_ie[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "m_day_ie (Model)                (None, 48)           19392       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inp_root_ie (InputLayer)        (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 52)           0           m_day_ie[2][0]                   \n",
      "                                                                 inp_root_ie[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "m_root_ie (Model)               (None, 1)            28465       concatenate_7[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 57,841\n",
      "Trainable params: 57,841\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def preproc_root(rec):\n",
    "    return np.array([(rec['age']-12)/70, rec['gender'], rec['n_children']/5., rec['income']])\n",
    "\n",
    "#model\n",
    "root_shape = (4,)\n",
    "inp = L.Input( (root_shape[0]+day_ie.model.output_shape[-1],) )\n",
    "x = inp\n",
    "for k in range(nn_depth):\n",
    "    x = L.Dense(nn_hidden_sizes,activation='relu')(x)\n",
    "x = L.Dense(1, activation='sigmoid')(x)\n",
    "root_model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "root_ie = IE.IntelligentElement(x_train, root_model, root_shape, preprocess_function=preproc_root, children_ie=[day_ie],\n",
    "                                val_data=x_val, test_data=x_test, name='root_ie')\n",
    "\n",
    "m, ii, oo = root_ie.retrieve_model_inputs_outputs()\n",
    "print('\\n\\nRetrieved model')\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55XWFvYKJBtB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hjmACG_nJBtI"
   },
   "source": [
    "# Training\n",
    "\n",
    "Using the generator to get data batches is recommended because IntelligentElement framework pads to the correct list size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dpC6whLJBtM"
   },
   "outputs": [],
   "source": [
    "train_gen = IE.IEDataGenerator(root_ie, y_train, from_set = 'train', batch_size=128, labeltype=int, shuffle=True)\n",
    "val_gen   = IE.IEDataGenerator(root_ie, y_val,   from_set = 'val',   batch_size=128, labeltype=int, shuffle=False)\n",
    "test_gen  = IE.IEDataGenerator(root_ie, y_test,  from_set = 'test',  batch_size=128, labeltype=int, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eyqCbUtPJBtV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qr-Ib4i7JBte"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "m.compile(optimizer=Adam(lr=1e-3, clipvalue=0.5), loss='binary_crossentropy', metrics=['binary_accuracy']) #, metrics=[mean_iou, 'categorical_accuracy'])\n",
    "\n",
    "earlystopper = EarlyStopping(patience=15, verbose=1, monitor='val_binary_accuracy')\n",
    "checkpointer = ModelCheckpoint('model-customer_pred.h5', verbose=1, save_best_only=True, monitor='val_binary_accuracy')\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-5, verbose=1, monitor='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1303
    },
    "colab_type": "code",
    "id": "HUws880dJBti",
    "outputId": "8e3ee851-dadb-4b35-e384-6bc91917f619",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1171/1171 [==============================] - 65s 56ms/step - loss: 0.4125 - binary_accuracy: 0.8036 - val_loss: 0.6094 - val_binary_accuracy: 0.7257\n",
      "\n",
      "Epoch 00001: val_binary_accuracy improved from -inf to 0.72569, saving model to model-customer_pred.h5\n",
      "Epoch 2/100\n",
      "1171/1171 [==============================] - 63s 54ms/step - loss: 0.4034 - binary_accuracy: 0.8082 - val_loss: 0.5797 - val_binary_accuracy: 0.7196\n",
      "\n",
      "Epoch 00002: val_binary_accuracy did not improve from 0.72569\n",
      "Epoch 3/100\n",
      "1171/1171 [==============================] - 64s 55ms/step - loss: 0.3963 - binary_accuracy: 0.8114 - val_loss: 0.5983 - val_binary_accuracy: 0.7283\n",
      "\n",
      "Epoch 00003: val_binary_accuracy improved from 0.72569 to 0.72830, saving model to model-customer_pred.h5\n",
      "Epoch 4/100\n",
      "1171/1171 [==============================] - 64s 55ms/step - loss: 0.3905 - binary_accuracy: 0.8157 - val_loss: 0.6405 - val_binary_accuracy: 0.7196\n",
      "\n",
      "Epoch 00004: val_binary_accuracy did not improve from 0.72830\n",
      "Epoch 5/100\n",
      "1171/1171 [==============================] - 64s 54ms/step - loss: 0.3851 - binary_accuracy: 0.8181 - val_loss: 0.6474 - val_binary_accuracy: 0.7005\n",
      "\n",
      "Epoch 00005: val_binary_accuracy did not improve from 0.72830\n",
      "Epoch 6/100\n",
      "1171/1171 [==============================] - 64s 54ms/step - loss: 0.3773 - binary_accuracy: 0.8219 - val_loss: 0.6974 - val_binary_accuracy: 0.6910\n",
      "\n",
      "Epoch 00006: val_binary_accuracy did not improve from 0.72830\n",
      "Epoch 7/100\n",
      "1171/1171 [==============================] - 64s 55ms/step - loss: 0.3668 - binary_accuracy: 0.8283 - val_loss: 0.7064 - val_binary_accuracy: 0.7092\n",
      "\n",
      "Epoch 00007: val_binary_accuracy did not improve from 0.72830\n",
      "Epoch 8/100\n",
      "1171/1171 [==============================] - 64s 54ms/step - loss: 0.3458 - binary_accuracy: 0.8390 - val_loss: 0.7356 - val_binary_accuracy: 0.7040\n",
      "\n",
      "Epoch 00008: val_binary_accuracy did not improve from 0.72830\n",
      "Epoch 9/100\n",
      "1171/1171 [==============================] - 64s 54ms/step - loss: 0.3258 - binary_accuracy: 0.8502 - val_loss: 0.8548 - val_binary_accuracy: 0.6953\n",
      "\n",
      "Epoch 00009: val_binary_accuracy did not improve from 0.72830\n",
      "Epoch 10/100\n",
      "1171/1171 [==============================] - 64s 55ms/step - loss: 0.3062 - binary_accuracy: 0.8602 - val_loss: 0.8653 - val_binary_accuracy: 0.6719\n",
      "\n",
      "Epoch 00010: val_binary_accuracy did not improve from 0.72830\n",
      "Epoch 11/100\n",
      "1171/1171 [==============================] - 64s 54ms/step - loss: 0.2898 - binary_accuracy: 0.8695 - val_loss: 0.8875 - val_binary_accuracy: 0.6892\n",
      "\n",
      "Epoch 00011: val_binary_accuracy did not improve from 0.72830\n",
      "Epoch 12/100\n",
      "1171/1171 [==============================] - 64s 55ms/step - loss: 0.2730 - binary_accuracy: 0.8786 - val_loss: 0.9906 - val_binary_accuracy: 0.6736\n",
      "\n",
      "Epoch 00012: val_binary_accuracy did not improve from 0.72830\n",
      "Epoch 13/100\n",
      "1171/1171 [==============================] - 64s 55ms/step - loss: 0.2594 - binary_accuracy: 0.8838 - val_loss: 1.0958 - val_binary_accuracy: 0.6771\n",
      "\n",
      "Epoch 00013: val_binary_accuracy did not improve from 0.72830\n",
      "Epoch 14/100\n",
      "1171/1171 [==============================] - 64s 54ms/step - loss: 0.2426 - binary_accuracy: 0.8932 - val_loss: 1.1886 - val_binary_accuracy: 0.6736\n",
      "\n",
      "Epoch 00014: val_binary_accuracy did not improve from 0.72830\n",
      "Epoch 15/100\n",
      "1171/1171 [==============================] - 63s 54ms/step - loss: 0.2302 - binary_accuracy: 0.8980 - val_loss: 1.1155 - val_binary_accuracy: 0.6580\n",
      "\n",
      "Epoch 00015: val_binary_accuracy did not improve from 0.72830\n",
      "Epoch 16/100\n",
      "1171/1171 [==============================] - 64s 54ms/step - loss: 0.2195 - binary_accuracy: 0.9034 - val_loss: 1.5486 - val_binary_accuracy: 0.6623\n",
      "\n",
      "Epoch 00016: val_binary_accuracy did not improve from 0.72830\n",
      "Epoch 17/100\n",
      "1171/1171 [==============================] - 64s 55ms/step - loss: 0.2090 - binary_accuracy: 0.9078 - val_loss: 1.2622 - val_binary_accuracy: 0.6892\n",
      "\n",
      "Epoch 00017: val_binary_accuracy did not improve from 0.72830\n",
      "Epoch 18/100\n",
      "1171/1171 [==============================] - 64s 55ms/step - loss: 0.2024 - binary_accuracy: 0.9111 - val_loss: 1.1515 - val_binary_accuracy: 0.6701\n",
      "\n",
      "Epoch 00018: val_binary_accuracy did not improve from 0.72830\n",
      "Epoch 00018: early stopping\n"
     ]
    }
   ],
   "source": [
    "results = m.fit_generator(train_gen, epochs=100, \n",
    "                          #use_multiprocessing = False, workers=4,\n",
    "                          validation_data=val_gen,\n",
    "                          callbacks=[earlystopper, checkpointer, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fYS0osOqJBto"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "iIneFKg3JBtr",
    "outputId": "448c251d-f8de-4256-f72f-5e02bc72f77b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1171/1171 [==============================] - 43s 37ms/step\n",
      "9/9 [==============================] - 0s 37ms/step\n",
      "7/7 [==============================] - 0s 34ms/step\n",
      "Train: [0.19080555304108676, 0.9172115179333903]\n",
      "Val:[1.1515069471465216, 0.6701388888888888]\n",
      "Test[1.188374902520861, 0.6863839285714286]\n"
     ]
    }
   ],
   "source": [
    "train_eval = m.evaluate_generator(train_gen, verbose=1)\n",
    "val_eval   = m.evaluate_generator(val_gen, verbose=1)\n",
    "test_eval  = m.evaluate_generator(test_gen, verbose=1)\n",
    "print('Train: {}\\nVal:{}\\nTest{}'.format(train_eval,val_eval,test_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mBhKMTh6Kv8S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Simple customer prediction.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
